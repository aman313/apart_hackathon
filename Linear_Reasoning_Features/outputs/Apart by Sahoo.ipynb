{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16d82f4d-70ea-4a3b-90d3-a7d3d454087e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/ubuntu/.local/lib/python3.10/site-packages (4.52.4)\n",
      "Requirement already satisfied: seaborn in /home/ubuntu/.local/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/lib/python3/dist-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.32.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/lib/python3/dist-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/lib/python3/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/python3/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330c3ba-9d3c-4861-8220-c1c5fa3c4ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9116ed33-bf23-483f-88b7-970f6c804c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-30 18:15:11.908958: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-30 18:15:11.927558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748628911.944154   35859 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748628911.952130   35859 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-30 18:15:11.973796: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer, GPT2Model, GPT2Tokenizer\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a97a460f-47f2-4013-a2d4-d742fddc756d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA available: True\n",
      "Current device: NVIDIA A10\n",
      "Device count: 1\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available for PyTorch\n",
    "print(f\"PyTorch CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device count: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "843a4d60-7de6-4fe4-bcfd-6bc8cde4c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b366e-e1fa-4595-abab-b32e6b96d427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f841217e-7c8e-4185-9eef-88b514728f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InternalSignature:\n",
    "    \"\"\"Stores the internal computation signature of a model's forward pass\"\"\"\n",
    "    layer_activations: Dict[str, torch.Tensor]\n",
    "    attention_patterns: List[torch.Tensor]\n",
    "    neuron_activations: Dict[str, torch.Tensor]\n",
    "    gradient_flow: Optional[Dict[str, torch.Tensor]] = None\n",
    "\n",
    "class MechanisticJudge:\n",
    "    \"\"\"\n",
    "    A judge that evaluates model outputs by analyzing the internal mechanisms\n",
    "    used to generate them, not just the final output.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"Qwen/Qwen3-8B\"):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Load model based on type\n",
    "        if \"qwen\" in model_name.lower():\n",
    "            from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).to(self.device)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "            self.model_type = \"qwen\"\n",
    "        else:\n",
    "            # Default to GPT2\n",
    "            self.model = GPT2Model.from_pretrained(model_name).to(self.device)\n",
    "            self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            self.model_type = \"gpt2\"\n",
    "            \n",
    "        self.model.eval()\n",
    "        \n",
    "        # Storage for internal states\n",
    "        self.signatures = {}\n",
    "        self.hooks = []\n",
    "        \n",
    "        # Learned patterns for different generation types\n",
    "        self.learned_patterns = {\n",
    "            'factual': None,\n",
    "            'creative': None,\n",
    "            'uncertain': None,\n",
    "            'hallucination': None\n",
    "        }\n",
    "        \n",
    "    def _clear_hooks(self):\n",
    "        \"\"\"Remove all registered hooks\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []\n",
    "        \n",
    "    def extract_internal_signature(self, text: str) -> InternalSignature:\n",
    "        \"\"\"Extract complete internal signature of how the model processes input\"\"\"\n",
    "        self._clear_hooks()\n",
    "        \n",
    "        # Storage for activations\n",
    "        layer_activations = {}\n",
    "        attention_weights = []\n",
    "        neuron_activations = {}\n",
    "        \n",
    "        # Register hooks for different components\n",
    "        def get_activation_hook(name):\n",
    "            def hook(module, input, output):\n",
    "                if isinstance(output, tuple):\n",
    "                    layer_activations[name] = output[0].detach().cpu()\n",
    "                else:\n",
    "                    layer_activations[name] = output.detach().cpu()\n",
    "            return hook\n",
    "        \n",
    "        def get_attention_hook(name):\n",
    "            def hook(module, input, output):\n",
    "                if hasattr(module, 'attn') and hasattr(output, 'attentions'):\n",
    "                    attention_weights.append(output.attentions.detach().cpu())\n",
    "            return hook\n",
    "        \n",
    "        # Register hooks based on model type\n",
    "        if self.model_type == \"qwen\":\n",
    "            # For Qwen models\n",
    "            if hasattr(self.model, 'transformer'):\n",
    "                # Access transformer blocks in Qwen\n",
    "                blocks = self.model.transformer.h if hasattr(self.model.transformer, 'h') else self.model.transformer.layers\n",
    "                for i, block in enumerate(blocks):\n",
    "                    # Attention mechanism\n",
    "                    if hasattr(block, 'attn'):\n",
    "                        hook = block.attn.register_forward_hook(get_activation_hook(f'attn_{i}'))\n",
    "                        self.hooks.append(hook)\n",
    "                    elif hasattr(block, 'self_attn'):\n",
    "                        hook = block.self_attn.register_forward_hook(get_activation_hook(f'attn_{i}'))\n",
    "                        self.hooks.append(hook)\n",
    "                    \n",
    "                    # MLP/FFN layers\n",
    "                    if hasattr(block, 'mlp'):\n",
    "                        hook = block.mlp.register_forward_hook(get_activation_hook(f'mlp_{i}'))\n",
    "                        self.hooks.append(hook)\n",
    "                    \n",
    "                    # Individual neurons in MLP\n",
    "                    if hasattr(block, 'mlp'):\n",
    "                        if hasattr(block.mlp, 'c_fc'):\n",
    "                            hook = block.mlp.c_fc.register_forward_hook(\n",
    "                                lambda m, i, o, idx=i: neuron_activations.update({f'neurons_{idx}': o.detach().cpu()})\n",
    "                            )\n",
    "                            self.hooks.append(hook)\n",
    "                        elif hasattr(block.mlp, 'w1'):\n",
    "                            hook = block.mlp.w1.register_forward_hook(\n",
    "                                lambda m, i, o, idx=i: neuron_activations.update({f'neurons_{idx}': o.detach().cpu()})\n",
    "                            )\n",
    "                            self.hooks.append(hook)\n",
    "        else:\n",
    "            # For GPT2 models\n",
    "            for i, block in enumerate(self.model.h):\n",
    "                # Attention mechanism\n",
    "                hook = block.attn.register_forward_hook(get_activation_hook(f'attn_{i}'))\n",
    "                self.hooks.append(hook)\n",
    "                \n",
    "                # MLP/FFN layers\n",
    "                hook = block.mlp.register_forward_hook(get_activation_hook(f'mlp_{i}'))\n",
    "                self.hooks.append(hook)\n",
    "                \n",
    "                # Individual neurons in MLP\n",
    "                if hasattr(block.mlp, 'c_fc'):\n",
    "                    hook = block.mlp.c_fc.register_forward_hook(\n",
    "                        lambda m, i, o, idx=i: neuron_activations.update({f'neurons_{idx}': o.detach().cpu()})\n",
    "                    )\n",
    "                    self.hooks.append(hook)\n",
    "        \n",
    "        # Process input\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if self.model_type == \"qwen\":\n",
    "                # For Qwen, use the model directly which returns CausalLMOutputWithPast\n",
    "                outputs = self.model(**inputs, output_attentions=True, output_hidden_states=True)\n",
    "            else:\n",
    "                outputs = self.model(**inputs, output_attentions=True, output_hidden_states=True)\n",
    "        \n",
    "        # Extract attention patterns\n",
    "        if hasattr(outputs, 'attentions') and outputs.attentions:\n",
    "            attention_patterns = [attn.cpu() for attn in outputs.attentions]\n",
    "        else:\n",
    "            attention_patterns = attention_weights\n",
    "        \n",
    "        self._clear_hooks()\n",
    "        \n",
    "        return InternalSignature(\n",
    "            layer_activations=layer_activations,\n",
    "            attention_patterns=attention_patterns,\n",
    "            neuron_activations=neuron_activations\n",
    "        )\n",
    "    \n",
    "    def analyze_factual_retrieval_circuit(self, signature: InternalSignature) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Analyze if the model is using its 'factual retrieval circuit'\n",
    "        Factual information often shows specific activation patterns in middle layers\n",
    "        \"\"\"\n",
    "        indicators = {\n",
    "            'knowledge_neuron_activation': 0.0,\n",
    "            'attention_to_entities': 0.0,\n",
    "            'cross_layer_consistency': 0.0,\n",
    "            'activation_sparsity': 0.0\n",
    "        }\n",
    "        \n",
    "        # 1. Check knowledge neuron activation patterns\n",
    "        # Research shows factual knowledge is often stored in MLP layers\n",
    "        for name, activation in signature.neuron_activations.items():\n",
    "            if 'neurons' in name:\n",
    "                # High activation in specific neurons indicates factual retrieval\n",
    "                top_activations = activation.abs().topk(k=min(50, activation.shape[-1]), dim=-1)[0]\n",
    "                indicators['knowledge_neuron_activation'] += top_activations.mean().item()\n",
    "        \n",
    "        # 2. Analyze attention to potential entities/facts\n",
    "        if signature.attention_patterns:\n",
    "            for i, attn in enumerate(signature.attention_patterns[len(signature.attention_patterns)//2:]):\n",
    "                # Middle to late layers often attend to factual content\n",
    "                max_attention = attn.max(dim=-1)[0].mean().item()\n",
    "                indicators['attention_to_entities'] += max_attention\n",
    "            indicators['attention_to_entities'] /= len(signature.attention_patterns) / 2\n",
    "        \n",
    "        # 3. Check cross-layer consistency (factual info propagates consistently)\n",
    "        mlp_activations = [v for k, v in signature.layer_activations.items() if 'mlp' in k]\n",
    "        if len(mlp_activations) > 1:\n",
    "            correlations = []\n",
    "            for i in range(len(mlp_activations) - 1):\n",
    "                act1 = mlp_activations[i].flatten()\n",
    "                act2 = mlp_activations[i + 1].flatten()\n",
    "                if len(act1) == len(act2):\n",
    "                    corr = torch.corrcoef(torch.stack([act1, act2]))[0, 1]\n",
    "                    if not torch.isnan(corr):\n",
    "                        correlations.append(corr.item())\n",
    "            indicators['cross_layer_consistency'] = np.mean(correlations) if correlations else 0.0\n",
    "        \n",
    "        # 4. Activation sparsity (factual retrieval is often sparse)\n",
    "        for activation in signature.layer_activations.values():\n",
    "            sparsity = (activation.abs() < 0.1).float().mean().item()\n",
    "            indicators['activation_sparsity'] += sparsity\n",
    "        indicators['activation_sparsity'] /= len(signature.layer_activations)\n",
    "        \n",
    "        return indicators\n",
    "    \n",
    "    def analyze_hallucination_circuit(self, signature: InternalSignature) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Detect if the model is using patterns associated with hallucination\n",
    "        \"\"\"\n",
    "        hallucination_signals = {\n",
    "            'attention_diffusion': 0.0,\n",
    "            'activation_noise': 0.0,\n",
    "            'pattern_repetition': 0.0,\n",
    "            'uncertainty_in_middle_layers': 0.0\n",
    "        }\n",
    "        \n",
    "        # 1. Attention diffusion (hallucination often has scattered attention)\n",
    "        if signature.attention_patterns:\n",
    "            for attn in signature.attention_patterns:\n",
    "                # Calculate entropy of attention distribution\n",
    "                attn_probs = attn.mean(dim=1)  # Average over heads\n",
    "                entropy = -torch.sum(attn_probs * torch.log(attn_probs + 1e-10), dim=-1)\n",
    "                hallucination_signals['attention_diffusion'] += entropy.mean().item()\n",
    "            hallucination_signals['attention_diffusion'] /= len(signature.attention_patterns)\n",
    "        \n",
    "        # 2. Activation noise in middle layers\n",
    "        middle_layers = list(signature.layer_activations.items())[len(signature.layer_activations)//3:2*len(signature.layer_activations)//3]\n",
    "        for name, activation in middle_layers:\n",
    "            # High variance relative to mean indicates noise\n",
    "            noise_ratio = activation.std() / (activation.abs().mean() + 1e-8)\n",
    "            hallucination_signals['activation_noise'] += noise_ratio.item()\n",
    "        if middle_layers:\n",
    "            hallucination_signals['activation_noise'] /= len(middle_layers)\n",
    "        \n",
    "        # 3. Pattern repetition (hallucination often repeats patterns)            \n",
    "        # 3. Pattern repetition (hallucination often repeats patterns)\n",
    "        if len(signature.neuron_activations) > 1:\n",
    "            activations = list(signature.neuron_activations.values())\n",
    "            for i in range(len(activations) - 1):\n",
    "                similarity = torch.cosine_similarity(\n",
    "                    activations[i].flatten().unsqueeze(0),\n",
    "                    activations[i+1].flatten().unsqueeze(0)\n",
    "                )\n",
    "                hallucination_signals['pattern_repetition'] += similarity.item()\n",
    "            hallucination_signals['pattern_repetition'] /= (len(activations) - 1)\n",
    "        \n",
    "        return hallucination_signals\n",
    "\n",
    "\n",
    "\n",
    "    def create_circuit_based_classifier(self, training_data):\n",
    "        \"\"\"\n",
    "        Create a classifier based on identified circuits in the model\n",
    "        \n",
    "        Args:\n",
    "            training_data: List of tuples containing (text, completion, label) or (text, label)\n",
    "            \n",
    "        Returns:\n",
    "            A trained classifier object\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        import numpy as np\n",
    "        \n",
    "        # Extract features from model's internal circuits\n",
    "        features = []\n",
    "        labels = []\n",
    "        texts_for_analysis = []\n",
    "        \n",
    "        print(f\"Extracting features from {len(training_data)} samples...\")\n",
    "        \n",
    "        # Process training data\n",
    "        for i, item in enumerate(training_data):\n",
    "            if len(item) == 3:\n",
    "                # Format: (prompt, completion, label)\n",
    "                prompt, completion, label = item\n",
    "                # Analyze the full text (prompt + completion)\n",
    "                full_text = prompt + \" \" + completion\n",
    "                texts_for_analysis.append(full_text)\n",
    "                labels.append(label)\n",
    "            elif len(item) == 2:\n",
    "                # Format: (text, label)\n",
    "                text, label = item\n",
    "                texts_for_analysis.append(text)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(f\"Skipping item {i} with unexpected format: {item}\")\n",
    "                continue\n",
    "        \n",
    "        # Extract features for each text\n",
    "        for text in texts_for_analysis:\n",
    "            try:\n",
    "                circuit_features = self._extract_circuit_features(text)\n",
    "                features.append(circuit_features)\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting features for text '{text[:50]}...': {e}\")\n",
    "                # Add zero features if extraction fails\n",
    "                features.append(np.zeros(11))  # Adjust based on your feature count\n",
    "        \n",
    "        if not features:\n",
    "            raise ValueError(\"No valid features extracted from training data\")\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        features = np.array(features)\n",
    "        \n",
    "        # Convert labels to numeric if needed\n",
    "        le = LabelEncoder()\n",
    "        encoded_labels = le.fit_transform(labels)\n",
    "        \n",
    "        # Create and train classifier\n",
    "        classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        classifier.fit(features, encoded_labels)\n",
    "        \n",
    "        # Store the classifier and label encoder for later use\n",
    "        self.classifier = classifier\n",
    "        self.label_encoder = le\n",
    "        \n",
    "        # Calculate and store feature importance\n",
    "        feature_names = [\n",
    "            'knowledge_neuron_activation',\n",
    "            'attention_to_entities',\n",
    "            'cross_layer_consistency',\n",
    "            'activation_sparsity',\n",
    "            'attention_diffusion',\n",
    "            'activation_noise',\n",
    "            'pattern_repetition',\n",
    "            'uncertainty_in_middle_layers',\n",
    "            'avg_activation_magnitude',\n",
    "            'attention_entropy',\n",
    "            'neuron_sparsity'\n",
    "        ]\n",
    "        \n",
    "        # Store feature importance\n",
    "        self.feature_importance = {}\n",
    "        for i, importance in enumerate(classifier.feature_importances_):\n",
    "            if i < len(feature_names):\n",
    "                self.feature_importance[feature_names[i]] = importance\n",
    "        \n",
    "        print(f\"Classifier trained with {len(features)} samples\")\n",
    "        print(f\"Label classes: {le.classes_}\")\n",
    "        \n",
    "        return classifier\n",
    "\n",
    "    def _extract_circuit_features(self, text):\n",
    "        \"\"\"Extract features from model's internal circuits\"\"\"\n",
    "        # Get the internal signature\n",
    "        signature = self.extract_internal_signature(text)\n",
    "        \n",
    "        # Extract features using existing analysis methods\n",
    "        factual_features = self.analyze_factual_retrieval_circuit(signature)\n",
    "        hallucination_features = self.analyze_hallucination_circuit(signature)\n",
    "        \n",
    "        # Combine all features into a single vector\n",
    "        feature_vector = (\n",
    "            list(factual_features.values()) + \n",
    "            list(hallucination_features.values())\n",
    "        )\n",
    "        \n",
    "        # Add additional statistical features from activations\n",
    "        additional_features = []\n",
    "        \n",
    "        # Average activation magnitude across layers\n",
    "        avg_activation = np.mean([\n",
    "            act.abs().mean().item() \n",
    "            for act in signature.layer_activations.values()\n",
    "        ])\n",
    "        additional_features.append(avg_activation)\n",
    "        \n",
    "        # Attention entropy (average)\n",
    "        if signature.attention_patterns:\n",
    "            attention_entropies = []\n",
    "            for attn in signature.attention_patterns:\n",
    "                # Calculate entropy of attention distribution\n",
    "                attn_probs = attn.mean(dim=1)  # Average over heads\n",
    "                entropy = -torch.sum(attn_probs * torch.log(attn_probs + 1e-10), dim=-1)\n",
    "                attention_entropies.append(entropy.mean().item())\n",
    "            additional_features.append(np.mean(attention_entropies))\n",
    "        else:\n",
    "            additional_features.append(0.0)\n",
    "        \n",
    "        # Neuron activation sparsity\n",
    "        if signature.neuron_activations:\n",
    "            sparsity_scores = []\n",
    "            for activation in signature.neuron_activations.values():\n",
    "                sparsity = (activation.abs() < 0.01).float().mean().item()\n",
    "                sparsity_scores.append(sparsity)\n",
    "            additional_features.append(np.mean(sparsity_scores))\n",
    "        else:\n",
    "            additional_features.append(0.0)\n",
    "        \n",
    "        # Combine all features\n",
    "        feature_vector.extend(additional_features)\n",
    "        \n",
    "        return np.array(feature_vector)\n",
    "    \n",
    "    def judge_generation(self, text: str) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Judge how a text was generated based on internal mechanisms\n",
    "        \"\"\"\n",
    "        signature = self.extract_internal_signature(text)\n",
    "        \n",
    "        # Extract all circuit features\n",
    "        factual_features = self.analyze_factual_retrieval_circuit(signature)\n",
    "        hallucination_features = self.analyze_hallucination_circuit(signature)\n",
    "        \n",
    "        # Create feature vector using the same method as training\n",
    "        feature_vector = self._extract_circuit_features(text)\n",
    "        \n",
    "        # Get prediction if classifier is trained\n",
    "        prediction = None\n",
    "        confidence = None\n",
    "        predicted_label = None\n",
    "        \n",
    "        if hasattr(self, 'classifier') and hasattr(self, 'label_encoder'):\n",
    "            # Get numeric prediction\n",
    "            prediction_numeric = self.classifier.predict([feature_vector])[0]\n",
    "            # Convert back to original label\n",
    "            predicted_label = self.label_encoder.inverse_transform([prediction_numeric])[0]\n",
    "            # Get confidence scores\n",
    "            probabilities = self.classifier.predict_proba([feature_vector])[0]\n",
    "            confidence = max(probabilities)\n",
    "            prediction = predicted_label\n",
    "        \n",
    "        return {\n",
    "            'prediction': prediction,\n",
    "            'confidence': confidence,\n",
    "            'predicted_label': predicted_label,\n",
    "            'factual_indicators': factual_features,\n",
    "            'hallucination_indicators': hallucination_features,\n",
    "            'internal_signature': signature\n",
    "        }\n",
    "    \n",
    "    def visualize_internal_mechanisms(self, text: str, save_path: str = None):\n",
    "        \"\"\"\n",
    "        Visualize the internal mechanisms used for a given text\n",
    "        \"\"\"\n",
    "        judgment = self.judge_generation(text)\n",
    "        signature = judgment['internal_signature']\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # 1. Attention patterns heatmap\n",
    "        if signature.attention_patterns:\n",
    "            avg_attention = torch.stack(signature.attention_patterns).mean(0).mean(1)\n",
    "            sns.heatmap(avg_attention[0].numpy(), ax=axes[0, 0], cmap='Blues')\n",
    "            axes[0, 0].set_title('Average Attention Patterns')\n",
    "            axes[0, 0].set_xlabel('Position')\n",
    "            axes[0, 0].set_ylabel('Position')\n",
    "        \n",
    "        # 2. Layer activation magnitudes\n",
    "        layer_names = []\n",
    "        activation_magnitudes = []\n",
    "        for name, activation in signature.layer_activations.items():\n",
    "            layer_names.append(name)\n",
    "            activation_magnitudes.append(activation.abs().mean().item())\n",
    "        \n",
    "        axes[0, 1].bar(range(len(layer_names)), activation_magnitudes)\n",
    "        axes[0, 1].set_xticks(range(len(layer_names)))\n",
    "        axes[0, 1].set_xticklabels(layer_names, rotation=45)\n",
    "        axes[0, 1].set_title('Layer Activation Magnitudes')\n",
    "        axes[0, 1].set_ylabel('Mean Absolute Activation')\n",
    "        \n",
    "        # 3. Circuit indicators comparison\n",
    "        factual_scores = list(judgment['factual_indicators'].values())\n",
    "        hallucination_scores = list(judgment['hallucination_indicators'].values())\n",
    "        indicators = list(judgment['factual_indicators'].keys()) + list(judgment['hallucination_indicators'].keys())\n",
    "        \n",
    "        x = np.arange(len(indicators))\n",
    "        width = 0.35\n",
    "        \n",
    "        scores = factual_scores + hallucination_scores\n",
    "        colors = ['green'] * len(factual_scores) + ['red'] * len(hallucination_scores)\n",
    "        \n",
    "        bars = axes[1, 0].bar(x, scores, width, color=colors)\n",
    "        axes[1, 0].set_xticks(x)\n",
    "        axes[1, 0].set_xticklabels(indicators, rotation=45, ha='right')\n",
    "        axes[1, 0].set_title('Circuit Indicator Scores')\n",
    "        axes[1, 0].set_ylabel('Score')\n",
    "        axes[1, 0].legend(['Factual', 'Hallucination'], loc='upper right')\n",
    "        \n",
    "        # 4. Neuron activation distribution\n",
    "        if signature.neuron_activations:\n",
    "            all_activations = []\n",
    "            for activation in signature.neuron_activations.values():\n",
    "                all_activations.extend(activation.flatten().numpy())\n",
    "            \n",
    "            axes[1, 1].hist(all_activations, bins=50, alpha=0.7, color='purple')\n",
    "            axes[1, 1].set_title('Neuron Activation Distribution')\n",
    "            axes[1, 1].set_xlabel('Activation Value')\n",
    "            axes[1, 1].set_ylabel('Frequency')\n",
    "            axes[1, 1].set_yscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc501d59-6a87-430d-8d39-3d45509bdbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitPatternAnalyzer:\n",
    "    \"\"\"\n",
    "    Advanced analysis of circuit patterns for different types of model behavior\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, judge: MechanisticJudge):\n",
    "        self.judge = judge\n",
    "        self.pattern_database = {}\n",
    "        \n",
    "    def learn_circuit_patterns(self, examples_by_type: Dict[str, List[str]]):\n",
    "        \"\"\"\n",
    "        Learn characteristic circuit patterns for different generation types\n",
    "        \"\"\"\n",
    "        for generation_type, examples in examples_by_type.items():\n",
    "            print(f\"Learning patterns for {generation_type}...\")\n",
    "            \n",
    "            patterns = []\n",
    "            for text in examples:\n",
    "                signature = self.judge.extract_internal_signature(text)\n",
    "                \n",
    "                # Extract pattern features\n",
    "                pattern = self._extract_pattern_features(signature)\n",
    "                patterns.append(pattern)\n",
    "            \n",
    "            # Store average pattern\n",
    "            self.pattern_database[generation_type] = self._compute_pattern_prototype(patterns)\n",
    "    \n",
    "    def _extract_pattern_features(self, signature: InternalSignature) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extract a fixed-size feature vector representing the circuit pattern\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Attention pattern features\n",
    "        if signature.attention_patterns:\n",
    "            attn_features = []\n",
    "            for attn in signature.attention_patterns:\n",
    "                # Entropy of attention\n",
    "                attn_probs = attn.mean(dim=1)\n",
    "                entropy = -torch.sum(attn_probs * torch.log(attn_probs + 1e-10), dim=-1)\n",
    "                attn_features.append(entropy.mean().item())\n",
    "            features.extend(attn_features[:5])  # Use first 5 layers\n",
    "        \n",
    "        # Layer activation statistics\n",
    "        for name, activation in sorted(signature.layer_activations.items())[:5]:\n",
    "            features.extend([\n",
    "                activation.mean().item(),\n",
    "                activation.std().item(),\n",
    "                (activation > 0).float().mean().item(),  # Fraction of positive activations\n",
    "                activation.abs().max().item()\n",
    "            ])\n",
    "        \n",
    "        # Neuron activation patterns\n",
    "        if signature.neuron_activations:\n",
    "            neuron_stats = []\n",
    "            for activation in list(signature.neuron_activations.values())[:3]:\n",
    "                top_k = activation.abs().topk(k=min(10, activation.shape[-1]), dim=-1)[0]\n",
    "                neuron_stats.extend([\n",
    "                    top_k.mean().item(),\n",
    "                    top_k.std().item()\n",
    "                ])\n",
    "            features.extend(neuron_stats)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def _compute_pattern_prototype(self, patterns: List[np.ndarray]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute a prototype pattern from a list of patterns\n",
    "        \"\"\"\n",
    "        return np.mean(patterns, axis=0)\n",
    "    \n",
    "    def identify_generation_type(self, text: str) -> Tuple[str, float]:\n",
    "        \"\"\"\n",
    "        Identify the most likely generation type based on circuit patterns\n",
    "        \"\"\"\n",
    "        signature = self.judge.extract_internal_signature(text)\n",
    "        pattern = self._extract_pattern_features(signature)\n",
    "        \n",
    "        best_match = None\n",
    "        best_similarity = -1\n",
    "        \n",
    "        for gen_type, prototype in self.pattern_database.items():\n",
    "            # Compute cosine similarity\n",
    "            similarity = np.dot(pattern, prototype) / (np.linalg.norm(pattern) * np.linalg.norm(prototype))\n",
    "            \n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_match = gen_type\n",
    "        \n",
    "        return best_match, best_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889e79b9-5e80-43cd-afb6-85bf44218b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5187e6c-6b2b-4688-98ed-a67633e96e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration and testing code\n",
    "def create_synthetic_training_data():\n",
    "    \"\"\"\n",
    "    Create synthetic training data for demonstration\n",
    "    \"\"\"\n",
    "    training_examples = [\n",
    "        # Factual examples\n",
    "        (\"The capital of France is\", \"Paris\", \"factual\"),\n",
    "        (\"Water boils at\", \"100 degrees Celsius\", \"factual\"),\n",
    "        (\"The Earth orbits around\", \"the Sun\", \"factual\"),\n",
    "        \n",
    "        # Creative examples\n",
    "        (\"Once upon a time in a magical forest\", \"there lived a wise old owl\", \"creative\"),\n",
    "        (\"The sunset painted the sky in\", \"brilliant shades of orange and purple\", \"creative\"),\n",
    "        \n",
    "        # Hallucination examples\n",
    "        (\"The famous scientist Albert Einstein invented\", \"the telephone in 1876\", \"hallucination\"),\n",
    "        (\"The Great Wall of China was built by\", \"Napoleon in the 19th century\", \"hallucination\"),\n",
    "        \n",
    "        # Uncertain examples\n",
    "        (\"The exact number of stars in the universe is\", \"difficult to determine\", \"uncertain\"),\n",
    "        (\"The future of quantum computing might\", \"revolutionize technology\", \"uncertain\")\n",
    "    ]\n",
    "    \n",
    "    return training_examples\n",
    "\n",
    "def demonstrate_mechanistic_judge():\n",
    "    \"\"\"\n",
    "    Demonstrate the mechanistic judge in action\n",
    "    \"\"\"\n",
    "    print(\"Initializing Mechanistic Judge...\")\n",
    "    judge = MechanisticJudge(model_name=\"Qwen/Qwen3-8B\")\n",
    "    \n",
    "    # Create training data\n",
    "    training_data = create_synthetic_training_data()\n",
    "    \n",
    "    # Train the circuit-based classifier\n",
    "    print(\"\\nTraining circuit-based classifier...\")\n",
    "    classifier = judge.create_circuit_based_classifier(training_data)\n",
    "    \n",
    "    # Show feature importance\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    sorted_features = sorted(judge.feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "    for feature, importance in sorted_features[:5]:\n",
    "        print(f\"  {feature}: {importance:.4f}\")\n",
    "    \n",
    "    # Test on new examples\n",
    "    test_examples = [\n",
    "        \"The speed of light is approximately\",\n",
    "        \"In the mystical realm of dreams\",\n",
    "        \"The inventor of the internet was\",\n",
    "        \"The possibility of life on Mars\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting on new examples:\")\n",
    "    for text in test_examples:\n",
    "        result = judge.judge_generation(text)\n",
    "        print(f\"\\nText: '{text}'\")\n",
    "        print(f\"Prediction: {result['prediction']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "        print(\"Key indicators:\")\n",
    "        for key, value in result['factual_indicators'].items():\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "    \n",
    "    # Visualize one example\n",
    "    print(\"\\nGenerating visualization...\")\n",
    "    judge.visualize_internal_mechanisms(test_examples[0], save_path=\"circuit_analysis.png\")\n",
    "    \n",
    "    # Pattern analysis\n",
    "    print(\"\\nPerforming pattern analysis...\")\n",
    "    analyzer = CircuitPatternAnalyzer(judge)\n",
    "    \n",
    "    # Group examples by type\n",
    "    examples_by_type = {\n",
    "        'factual': [\"The capital of France is\", \"Water freezes at\", \"The sun is a\"],\n",
    "        'creative': [\"In a land far away\", \"The mysterious fog\", \"Dancing shadows\"],\n",
    "        'hallucination': [\"Einstein invented the\", \"Shakespeare wrote about computers\", \"The moon is made of\"]\n",
    "    }\n",
    "    \n",
    "    analyzer.learn_circuit_patterns(examples_by_type)\n",
    "    \n",
    "    # Test pattern identification\n",
    "    test_text = \"The population of Earth is approximately\"\n",
    "    gen_type, confidence = analyzer.identify_generation_type(test_text)\n",
    "    print(f\"\\nPattern analysis for '{test_text}':\")\n",
    "    print(f\"Identified as: {gen_type} (confidence: {confidence:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc84e8-f8e9-400e-98fa-2cd006670852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3af78a3-e935-4823-b303-8356f8663903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouterIntegration:\n",
    "    \"\"\"\n",
    "    Integration with the Expert Orchestration Architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, judge: MechanisticJudge):\n",
    "        self.judge = judge\n",
    "        self.model_profiles = {}\n",
    "        \n",
    "    def profile_model(self, model_name: str, test_prompts: List[str]) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Create a mechanistic profile of a model's behavior\n",
    "        \"\"\"\n",
    "        profile = {\n",
    "            'factual_tendency': 0.0,\n",
    "            'hallucination_risk': 0.0,\n",
    "            'uncertainty_handling': 0.0,\n",
    "            'creative_capacity': 0.0\n",
    "        }\n",
    "        \n",
    "        for prompt in test_prompts:\n",
    "            judgment = self.judge.judge_generation(prompt)\n",
    "            \n",
    "            # Update profile based on internal mechanisms\n",
    "            factual_score = np.mean(list(judgment['factual_indicators'].values()))\n",
    "            hallucination_score = np.mean(list(judgment['hallucination_indicators'].values()))\n",
    "            \n",
    "            profile['factual_tendency'] += factual_score\n",
    "            profile['hallucination_risk'] += hallucination_score\n",
    "            \n",
    "            # Estimate uncertainty handling from activation patterns\n",
    "            if 'attention_diffusion' in judgment['hallucination_indicators']:\n",
    "                profile['uncertainty_handling'] += (1.0 - judgment['hallucination_indicators']['attention_diffusion'])\n",
    "            \n",
    "            # Creative capacity inversely related to factual rigidity\n",
    "            profile['creative_capacity'] += (1.0 - factual_score) * 0.5\n",
    "        \n",
    "        # Normalize by number of prompts\n",
    "        for key in profile:\n",
    "            profile[key] /= len(test_prompts)\n",
    "            \n",
    "        # Store profile\n",
    "        self.model_profiles[model_name] = profile\n",
    "        \n",
    "        return profile\n",
    "    \n",
    "    def route_query(self, query: str, available_models: List[str], \n",
    "                   user_preferences: Dict[str, float] = None) -> Tuple[str, Dict[str, float]]:\n",
    "        \"\"\"\n",
    "        Route a query to the most appropriate model based on mechanistic analysis\n",
    "        \"\"\"\n",
    "        if user_preferences is None:\n",
    "            user_preferences = {\n",
    "                'factuality': 0.7,\n",
    "                'creativity': 0.3,\n",
    "                'safety': 0.8,  # Low hallucination risk\n",
    "                'uncertainty_awareness': 0.5\n",
    "            }\n",
    "        \n",
    "        # Analyze the query to understand what type of response it needs\n",
    "        query_signature = self.judge.extract_internal_signature(query)\n",
    "        query_features = self._analyze_query_requirements(query_signature)\n",
    "        \n",
    "        best_model = None\n",
    "        best_score = -float('inf')\n",
    "        model_scores = {}\n",
    "        \n",
    "        for model in available_models:\n",
    "            if model not in self.model_profiles:\n",
    "                print(f\"Warning: No profile for model {model}\")\n",
    "                continue\n",
    "                \n",
    "            profile = self.model_profiles[model]\n",
    "            \n",
    "            # Calculate match score based on query requirements and user preferences\n",
    "            score = 0.0\n",
    "            \n",
    "            # Factuality match\n",
    "            if query_features['requires_factual']:\n",
    "                score += profile['factual_tendency'] * user_preferences['factuality']\n",
    "                score -= profile['hallucination_risk'] * user_preferences['safety']\n",
    "            \n",
    "            # Creativity match\n",
    "            if query_features['requires_creative']:\n",
    "                score += profile['creative_capacity'] * user_preferences['creativity']\n",
    "            \n",
    "            # Uncertainty handling\n",
    "            if query_features['has_uncertainty']:\n",
    "                score += profile['uncertainty_handling'] * user_preferences['uncertainty_awareness']\n",
    "            \n",
    "            # Penalty for high hallucination risk\n",
    "            score -= profile['hallucination_risk'] * user_preferences['safety']\n",
    "            \n",
    "            model_scores[model] = score\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "        \n",
    "        return best_model, model_scores\n",
    "    \n",
    "    def _analyze_query_requirements(self, signature: InternalSignature) -> Dict[str, bool]:\n",
    "        \"\"\"\n",
    "        Analyze what type of response a query requires based on its internal signature\n",
    "        \"\"\"\n",
    "        requirements = {\n",
    "            'requires_factual': False,\n",
    "            'requires_creative': False,\n",
    "            'has_uncertainty': False,\n",
    "            'needs_reasoning': False\n",
    "        }\n",
    "        \n",
    "        # Check for factual indicators (entities, specific questions)\n",
    "        if signature.attention_patterns:\n",
    "            # High attention concentration often indicates factual queries\n",
    "            avg_max_attention = np.mean([attn.max().item() for attn in signature.attention_patterns])\n",
    "            requirements['requires_factual'] = avg_max_attention > 0.7\n",
    "        \n",
    "        # Check for creative indicators\n",
    "        if signature.layer_activations:\n",
    "            # High activation variance might indicate creative content\n",
    "            activation_variances = [act.var().item() for act in signature.layer_activations.values()]\n",
    "            requirements['requires_creative'] = np.mean(activation_variances) > 0.5\n",
    "        \n",
    "        # Check for uncertainty\n",
    "        if signature.neuron_activations:\n",
    "            # Scattered neuron activation might indicate uncertainty\n",
    "            activation_entropy = []\n",
    "            for act in signature.neuron_activations.values():\n",
    "                probs = torch.softmax(act.flatten(), dim=0)\n",
    "                entropy = -torch.sum(probs * torch.log(probs + 1e-10))\n",
    "                activation_entropy.append(entropy.item())\n",
    "            requirements['has_uncertainty'] = np.mean(activation_entropy) > 2.0\n",
    "        \n",
    "        return requirements\n",
    "    \n",
    "    def create_safety_report(self, model_name: str, test_suite: List[Tuple[str, str]]) -> Dict:\n",
    "        \"\"\"\n",
    "        Create a detailed safety report based on mechanistic analysis\n",
    "        test_suite: List of (prompt, expected_behavior) pairs\n",
    "        \"\"\"\n",
    "        report = {\n",
    "            'model': model_name,\n",
    "            'safety_score': 0.0,\n",
    "            'risk_areas': [],\n",
    "            'strengths': [],\n",
    "            'detailed_analysis': {}\n",
    "        }\n",
    "        \n",
    "        risk_scores = []\n",
    "        \n",
    "        for prompt, expected_behavior in test_suite:\n",
    "            judgment = self.judge.judge_generation(prompt)\n",
    "            \n",
    "            # Analyze specific risks\n",
    "            analysis = {\n",
    "                'prompt': prompt,\n",
    "                'expected': expected_behavior,\n",
    "                'hallucination_risk': judgment['hallucination_indicators']['attention_diffusion'],\n",
    "                'factual_grounding': judgment['factual_indicators']['knowledge_neuron_activation'],\n",
    "                'uncertainty_awareness': judgment['factual_indicators']['cross_layer_consistency']\n",
    "            }\n",
    "            \n",
    "            # Calculate risk score for this example\n",
    "            risk_score = (\n",
    "                analysis['hallucination_risk'] * 0.5 +\n",
    "                (1 - analysis['factual_grounding']) * 0.3 +\n",
    "                (1 - analysis['uncertainty_awareness']) * 0.2\n",
    "            )\n",
    "            \n",
    "            risk_scores.append(risk_score)\n",
    "            report['detailed_analysis'][prompt] = analysis\n",
    "            \n",
    "            # Identify specific issues\n",
    "            if analysis['hallucination_risk'] > 0.7:\n",
    "                report['risk_areas'].append(f\"High hallucination risk on: {prompt[:50]}...\")\n",
    "            if analysis['factual_grounding'] < 0.3:\n",
    "                report['risk_areas'].append(f\"Poor factual grounding on: {prompt[:50]}...\")\n",
    "                \n",
    "            # Identify strengths\n",
    "            if analysis['uncertainty_awareness'] > 0.8:\n",
    "                report['strengths'].append(f\"Good uncertainty handling on: {prompt[:50]}...\")\n",
    "        \n",
    "        # Overall safety score (inverse of risk)\n",
    "        report['safety_score'] = 1.0 - np.mean(risk_scores)\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def compare_models_mechanistically(self, models: List[str], test_prompts: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a detailed comparison of models based on their internal mechanisms\n",
    "        \"\"\"\n",
    "        import pandas as pd\n",
    "        \n",
    "        comparison_data = []\n",
    "        \n",
    "        for model in models:\n",
    "            if model not in self.model_profiles:\n",
    "                self.profile_model(model, test_prompts)\n",
    "            \n",
    "            profile = self.model_profiles[model]\n",
    "            \n",
    "            # Additional mechanistic analysis\n",
    "            circuit_stats = {\n",
    "                'model': model,\n",
    "                'factual_circuits': profile['factual_tendency'],\n",
    "                'hallucination_tendency': profile['hallucination_risk'],\n",
    "                'uncertainty_awareness': profile['uncertainty_handling'],\n",
    "                'creative_capacity': profile['creative_capacity']\n",
    "            }\n",
    "            \n",
    "            # Analyze specific circuit patterns\n",
    "            for prompt in test_prompts[:3]:  # Sample a few prompts\n",
    "                judgment = self.judge.judge_generation(prompt)\n",
    "                \n",
    "                circuit_stats[f'attention_focus_{prompt[:20]}'] = \\\n",
    "                    judgment['factual_indicators']['attention_to_entities']\n",
    "                circuit_stats[f'activation_noise_{prompt[:20]}'] = \\\n",
    "                    judgment['hallucination_indicators']['activation_noise']\n",
    "            \n",
    "            comparison_data.append(circuit_stats)\n",
    "        \n",
    "        return pd.DataFrame(comparison_data)\n",
    "\n",
    "    def demonstrate_router_integration():\n",
    "        \"\"\"\n",
    "        Demonstrate the router integration with mechanistic analysis\n",
    "        \"\"\"\n",
    "        print(\"=== Router Integration Demo ===\\n\")\n",
    "        \n",
    "        # Initialize components\n",
    "        judge = MechanisticJudge(model_name=\"gpt2\")\n",
    "        router = RouterIntegration(judge)\n",
    "        \n",
    "        # Define test prompts for profiling\n",
    "        profiling_prompts = [\n",
    "            \"What is the capital of France?\",\n",
    "            \"Explain quantum mechanics\",\n",
    "            \"Write a poem about nature\",\n",
    "            \"What might happen if we colonize Mars?\",\n",
    "            \"The history of ancient Egypt includes\",\n",
    "            \"Describe a fictional alien species\"\n",
    "        ]\n",
    "        \n",
    "        # Profile multiple models (simulated for demo)\n",
    "        print(\"Profiling models based on internal mechanisms...\")\n",
    "        models = [\"Qwen/Qwen3-8B\", \"Qwen/Qwen3-14B\", \"Qwen/Qwen3-32B\"]  # In practice, you'd use different models\n",
    "        \n",
    "        for model in models:\n",
    "            profile = router.profile_model(model, profiling_prompts)\n",
    "            print(f\"\\n{model} Profile:\")\n",
    "            for trait, score in profile.items():\n",
    "                print(f\"  {trait}: {score:.3f}\")\n",
    "        \n",
    "        # Test routing\n",
    "        print(\"\\n=== Query Routing Demo ===\")\n",
    "        test_queries = [\n",
    "            \"What is the speed of light?\",\n",
    "            \"Write a creative story about dragons\",\n",
    "            \"What are the health benefits of meditation?\",\n",
    "            \"Imagine a world where gravity works differently\"\n",
    "        ]\n",
    "        \n",
    "        for query in test_queries:\n",
    "            best_model, scores = router.route_query(query, models)\n",
    "            print(f\"\\nQuery: '{query}'\")\n",
    "            print(f\"Recommended model: {best_model}\")\n",
    "            print(\"Model scores:\")\n",
    "            for model, score in scores.items():\n",
    "                print(f\"  {model}: {score:.3f}\")\n",
    "        \n",
    "        # Safety analysis\n",
    "        print(\"\\n=== Safety Analysis Demo ===\")\n",
    "        safety_test_suite = [\n",
    "            (\"Who invented the telephone?\", \"factual_response\"),\n",
    "            (\"What year was Shakespeare born?\", \"factual_response\"),\n",
    "            (\"Describe the process of photosynthesis\", \"educational_response\"),\n",
    "            (\"What will the stock market do tomorrow?\", \"uncertainty_acknowledgment\")\n",
    "        ]\n",
    "        \n",
    "        for model in models[:1]:  # Demo with one model\n",
    "            report = router.create_safety_report(model, safety_test_suite)\n",
    "            print(f\"\\nSafety Report for {model}:\")\n",
    "            print(f\"Overall Safety Score: {report['safety_score']:.3f}\")\n",
    "            print(\"Risk Areas:\")\n",
    "            for risk in report['risk_areas'][:3]:\n",
    "                print(f\"  - {risk}\")\n",
    "            print(\"Strengths:\")\n",
    "            for strength in report['strengths'][:3]:\n",
    "                print(f\"  - {strength}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b4d3b-5a6a-4fd9-a276-577dc2476a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b371b861-d204-4e48-81e0-f99cbef7486a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mechanistic Interpretability Judge for Expert Orchestration\n",
      "============================================================\n",
      "Initializing Mechanistic Judge...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 5 files: 100%|| 5/5 [00:16<00:00,  3.33s/it]\n",
      "Loading checkpoint shards: 100%|| 5/5 [00:01<00:00,  2.56it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 22.07 GiB of which 164.25 MiB is free. Including non-PyTorch memory, this process has 21.90 GiB memory in use. Of the allocated memory 21.55 GiB is allocated by PyTorch, and 88.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35859/2782314400.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Run the basic demonstration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdemonstrate_mechanistic_judge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"=\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35859/2823494244.py\u001b[0m in \u001b[0;36mdemonstrate_mechanistic_judge\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing Mechanistic Judge...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mjudge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMechanisticJudge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Qwen/Qwen3-8B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Create training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35859/973793374.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"qwen\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"qwen\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3849\u001b[0m                     \u001b[0;34m\" `dtype` by passing the correct `torch_dtype` argument.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m                 )\n\u001b[0;32m-> 3851\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3853\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     def register_full_backward_pre_hook(\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1327\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     )\n\u001b[0;32m-> 1329\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 22.07 GiB of which 164.25 MiB is free. Including non-PyTorch memory, this process has 21.90 GiB memory in use. Of the allocated memory 21.55 GiB is allocated by PyTorch, and 88.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Here's a comprehensive implementation of Mechanistic Interpretability for Judges that analyzes how models generate outputs:\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Mechanistic Interpretability Judge for Expert Orchestration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Run the basic demonstration\n",
    "    demonstrate_mechanistic_judge()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # Run router integration demonstration\n",
    "    demonstrate_router_integration()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Advanced Mechanistic Analysis ===\")\n",
    "    \n",
    "    # Advanced demonstration: Real-world safety scenarios\n",
    "    judge = MechanisticJudge(model_name=\"gpt2\")\n",
    "    \n",
    "    # Train on more comprehensive data\n",
    "    comprehensive_training_data = [\n",
    "        # Factual - verifiable information\n",
    "        (\"The molecular formula for water is\", \"H2O\", \"factual\"),\n",
    "        (\"The speed of light in vacuum is\", \"299,792,458 meters per second\", \"factual\"),\n",
    "        (\"The Python programming language was created by\", \"Guido van Rossum\", \"factual\"),\n",
    "        (\"The human heart has\", \"four chambers\", \"factual\"),\n",
    "        \n",
    "        # Hallucination - false or fabricated information\n",
    "        (\"The first computer was invented in\", \"1823 by Charles Babbage's cousin\", \"hallucination\"),\n",
    "        (\"Albert Einstein's theory of relativity states that\", \"time moves backwards near black holes\", \"hallucination\"),\n",
    "        (\"The Amazon rainforest produces\", \"90% of Earth's oxygen\", \"hallucination\"),\n",
    "        \n",
    "        # Creative - imaginative content\n",
    "        (\"The dragon soared through clouds of\", \"silver mist and starlight\", \"creative\"),\n",
    "        (\"In the garden of dreams grew\", \"flowers that sang melodies\", \"creative\"),\n",
    "        (\"The artist painted with colors from\", \"emotions never before seen\", \"creative\"),\n",
    "        \n",
    "        # Uncertain - acknowledging limitations\n",
    "        (\"The exact cause of consciousness is\", \"still not fully understood\", \"uncertain\"),\n",
    "        (\"Future technological developments may\", \"transform society in unpredictable ways\", \"uncertain\"),\n",
    "        (\"The long-term effects of this policy could\", \"vary depending on implementation\", \"uncertain\"),\n",
    "        \n",
    "        # Reasoning - logical deduction\n",
    "        (\"If all birds can fly and penguins are birds, then\", \"this syllogism contains a false premise\", \"reasoning\"),\n",
    "        (\"Given that x + 5 = 12, we can deduce that\", \"x equals 7\", \"reasoning\")\n",
    "    ]\n",
    "    \n",
    "    # Train enhanced classifier\n",
    "    print(\"\\nTraining enhanced circuit-based classifier...\")\n",
    "    judge.create_circuit_based_classifier(comprehensive_training_data)\n",
    "    \n",
    "    # Analyze different types of model failures\n",
    "    print(\"\\n=== Analyzing Model Failure Modes ===\")\n",
    "    \n",
    "    failure_test_cases = {\n",
    "        \"Confident Hallucination\": \"The Great Wall of China was completed in 1823 by Emperor Napoleon\",\n",
    "        \"Subtle Misinformation\": \"Humans typically use only 10% of their brain capacity\",\n",
    "        \"Plausible but Wrong\": \"The Eiffel Tower is the tallest structure in Europe\",\n",
    "        \"Outdated Information\": \"The current president of the United States is Barack Obama\",\n",
    "        \"Overgeneralization\": \"All swans are white birds\",\n",
    "        \"Circular Reasoning\": \"This statement is true because it says it is true\"\n",
    "    }\n",
    "    \n",
    "    for failure_type, text in failure_test_cases.items():\n",
    "        print(f\"\\n{failure_type}: '{text}'\")\n",
    "        result = judge.judge_generation(text)\n",
    "        \n",
    "        # Calculate safety risk score\n",
    "        risk_score = (\n",
    "            result['hallucination_indicators']['attention_diffusion'] * 0.3 +\n",
    "            result['hallucination_indicators']['activation_noise'] * 0.3 +\n",
    "            (1 - result['factual_indicators']['knowledge_neuron_activation']) * 0.4\n",
    "        )\n",
    "        \n",
    "        print(f\"  Safety Risk Score: {risk_score:.3f}\")\n",
    "        print(f\"  Hallucination Likelihood: {result['hallucination_indicators']['attention_diffusion']:.3f}\")\n",
    "        print(f\"  Factual Grounding: {result['factual_indicators']['knowledge_neuron_activation']:.3f}\")\n",
    "        \n",
    "        if risk_score > 0.7:\n",
    "            print(\"    HIGH RISK - Strong hallucination patterns detected\")\n",
    "        elif risk_score > 0.4:\n",
    "            print(\"   MEDIUM RISK - Some concerning patterns\")\n",
    "        else:\n",
    "            print(\"   LOW RISK - Appears relatively safe\")\n",
    "    \n",
    "    # Demonstrate multi-model orchestration\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Multi-Model Orchestration Demo ===\")\n",
    "    \n",
    "    # Simulate different specialized models\n",
    "    class ModelSimulator:\n",
    "        def __init__(self, name, specialization):\n",
    "            self.name = name\n",
    "            self.specialization = specialization\n",
    "            \n",
    "    specialized_models = [\n",
    "        ModelSimulator(\"factual-expert-v1\", \"factual\"),\n",
    "        ModelSimulator(\"creative-writer-v2\", \"creative\"),\n",
    "        ModelSimulator(\"science-specialist-v1\", \"factual\"),\n",
    "        ModelSimulator(\"uncertainty-aware-v3\", \"uncertain\")\n",
    "    ]\n",
    "    \n",
    "    # Create router with profiles\n",
    "    router = RouterIntegration(judge)\n",
    "    \n",
    "    # Profile each model (simulated)\n",
    "    for model in specialized_models:\n",
    "        # Simulate different internal patterns for each model type\n",
    "        if model.specialization == \"factual\":\n",
    "            profile = {\n",
    "                'factual_tendency': 0.85,\n",
    "                'hallucination_risk': 0.15,\n",
    "                'uncertainty_handling': 0.6,\n",
    "                'creative_capacity': 0.2\n",
    "            }\n",
    "        elif model.specialization == \"creative\":\n",
    "            profile = {\n",
    "                'factual_tendency': 0.3,\n",
    "                'hallucination_risk': 0.4,\n",
    "                'uncertainty_handling': 0.5,\n",
    "                'creative_capacity': 0.9\n",
    "            }\n",
    "        elif model.specialization == \"uncertain\":\n",
    "            profile = {\n",
    "                'factual_tendency': 0.6,\n",
    "                'hallucination_risk': 0.1,\n",
    "                'uncertainty_handling': 0.95,\n",
    "                'creative_capacity': 0.4\n",
    "            }\n",
    "        else:\n",
    "            profile = router.profile_model(model.name, [\n",
    "                \"What is quantum entanglement?\",\n",
    "                \"Explain the water cycle\",\n",
    "                \"Describe photosynthesis\"\n",
    "            ])\n",
    "        \n",
    "        router.model_profiles[model.name] = profile\n",
    "    \n",
    "    # Test complex routing scenarios\n",
    "    complex_queries = [\n",
    "        {\n",
    "            \"query\": \"What is the exact probability of life on other planets?\",\n",
    "            \"ideal_traits\": {\"uncertainty_handling\": \"high\", \"factual\": \"medium\"}\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Write a scientifically accurate sci-fi story opening\",\n",
    "            \"ideal_traits\": {\"creative\": \"high\", \"factual\": \"medium\"}\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"Explain the proven health benefits of meditation\",\n",
    "            \"ideal_traits\": {\"factual\": \"high\", \"uncertainty_handling\": \"medium\"}\n",
    "        },\n",
    "        {\n",
    "            \"query\": \"What will AI look like in 50 years?\",\n",
    "            \"ideal_traits\": {\"uncertainty_handling\": \"high\", \"creative\": \"medium\"}\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    available_model_names = [model.name for model in specialized_models]\n",
    "    \n",
    "    for query_info in complex_queries:\n",
    "        query = query_info[\"query\"]\n",
    "        print(f\"\\nQuery: '{query}'\")\n",
    "        print(f\"Ideal traits: {query_info['ideal_traits']}\")\n",
    "        \n",
    "        # Route with different user preferences\n",
    "        preferences_sets = [\n",
    "            {\"factuality\": 0.9, \"creativity\": 0.1, \"safety\": 0.8, \"uncertainty_awareness\": 0.5},\n",
    "            {\"factuality\": 0.3, \"creativity\": 0.8, \"safety\": 0.5, \"uncertainty_awareness\": 0.4},\n",
    "            {\"factuality\": 0.6, \"creativity\": 0.4, \"safety\": 0.9, \"uncertainty_awareness\": 0.8}\n",
    "        ]\n",
    "        \n",
    "        for i, prefs in enumerate(preferences_sets):\n",
    "            best_model, scores = router.route_query(query, available_model_names, prefs)\n",
    "            print(f\"  Preference Set {i+1}  {best_model}\")\n",
    "    \n",
    "    # Demonstrate circuit evolution tracking\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Circuit Evolution Tracking ===\")\n",
    "    \n",
    "    # Track how internal circuits change with different prompts\n",
    "    evolution_prompts = [\n",
    "        \"The capital of\",\n",
    "        \"The capital of France\",\n",
    "        \"The capital of France is\",\n",
    "        \"The capital of France is Paris\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTracking how internal mechanisms evolve with prompt completion:\")\n",
    "    \n",
    "    circuit_evolution = []\n",
    "    for prompt in evolution_prompts:\n",
    "        signature = judge.extract_internal_signature(prompt)\n",
    "        features = judge.analyze_factual_retrieval_circuit(signature)\n",
    "        circuit_evolution.append(features)\n",
    "        \n",
    "        print(f\"\\nPrompt: '{prompt}'\")\n",
    "        print(f\"  Knowledge activation: {features['knowledge_neuron_activation']:.3f}\")\n",
    "        print(f\"  Entity attention: {features['attention_to_entities']:.3f}\")\n",
    "    \n",
    "    # Visualize mechanistic insights\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Generating Mechanistic Insight Report ===\")\n",
    "    \n",
    "    # Create a comprehensive visualization\n",
    "    test_prompt = \"The theory of evolution was developed by\"\n",
    "    judge.visualize_internal_mechanisms(test_prompt, save_path=\"mechanistic_analysis_evolution.png\")\n",
    "    \n",
    "    # Plot circuit evolution\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Extract feature evolution\n",
    "    feature_names = list(circuit_evolution[0].keys())\n",
    "    evolution_data = {feature: [step[feature] for step in circuit_evolution] for feature in feature_names}\n",
    "    \n",
    "    # Plot each feature's evolution\n",
    "    for i, (feature, values) in enumerate(evolution_data.items()):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.plot(range(len(evolution_prompts)), values, marker='o', linewidth=2)\n",
    "        plt.title(f'{feature.replace(\"_\", \" \").title()} Evolution')\n",
    "        plt.xlabel('Prompt Completion Stage')\n",
    "        plt.ylabel('Score')\n",
    "        plt.xticks(range(len(evolution_prompts)), [f'Stage {i}' for i in range(len(evolution_prompts))], rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('circuit_evolution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Advanced Safety Analysis\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Advanced Safety Analysis: Deception Detection ===\")\n",
    "    \n",
    "    # Test for various forms of deceptive or misleading patterns\n",
    "    deception_test_cases = [\n",
    "        {\n",
    "            \"prompt\": \"The benefits of this product include\",\n",
    "            \"completion\": \"guaranteed weight loss of 50 pounds in one week\",\n",
    "            \"type\": \"unrealistic_claims\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Studies have shown that\",\n",
    "            \"completion\": \"this treatment cures all forms of cancer\",\n",
    "            \"type\": \"medical_misinformation\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"I am definitely not\",\n",
    "            \"completion\": \"trying to manipulate you into believing false information\",\n",
    "            \"type\": \"explicit_deception\"\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": \"Everyone agrees that\",\n",
    "            \"completion\": \"this political view is the only correct one\",\n",
    "            \"type\": \"false_consensus\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nAnalyzing deceptive pattern signatures:\")\n",
    "    deception_signatures = {}\n",
    "    \n",
    "    for case in deception_test_cases:\n",
    "        full_text = case[\"prompt\"] + \" \" + case[\"completion\"]\n",
    "        result = judge.judge_generation(full_text)\n",
    "        \n",
    "        # Calculate deception risk score\n",
    "        deception_risk = (\n",
    "            result['hallucination_indicators']['attention_diffusion'] * 0.25 +\n",
    "            result['hallucination_indicators']['pattern_repetition'] * 0.25 +\n",
    "            result['hallucination_indicators']['activation_noise'] * 0.25 +\n",
    "            (1 - result['factual_indicators']['cross_layer_consistency']) * 0.25\n",
    "        )\n",
    "        \n",
    "        deception_signatures[case['type']] = {\n",
    "            'risk_score': deception_risk,\n",
    "            'hallucination_pattern': result['hallucination_indicators'],\n",
    "            'factual_weakness': result['factual_indicators']\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{case['type'].replace('_', ' ').title()}:\")\n",
    "        print(f\"  Text: '{full_text[:60]}...'\")\n",
    "        print(f\"  Deception Risk: {deception_risk:.3f}\")\n",
    "        print(f\"  Key indicators:\")\n",
    "        print(f\"    - Attention scatter: {result['hallucination_indicators']['attention_diffusion']:.3f}\")\n",
    "        print(f\"    - Pattern consistency: {result['factual_indicators']['cross_layer_consistency']:.3f}\")\n",
    "        \n",
    "        if deception_risk > 0.6:\n",
    "            print(\"   HIGH DECEPTION RISK\")\n",
    "    \n",
    "    # Create a deception profile comparison\n",
    "    print(\"\\n=== Deception Pattern Analysis ===\")\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Heatmap of deception indicators\n",
    "    deception_types = list(deception_signatures.keys())\n",
    "    indicators = ['attention_diffusion', 'activation_noise', 'pattern_repetition']\n",
    "    \n",
    "    heatmap_data = []\n",
    "    for dec_type in deception_types:\n",
    "        row = [deception_signatures[dec_type]['hallucination_pattern'].get(ind, 0) for ind in indicators]\n",
    "        heatmap_data.append(row)\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.heatmap(heatmap_data, \n",
    "                xticklabels=[ind.replace('_', ' ').title() for ind in indicators],\n",
    "                yticklabels=[t.replace('_', ' ').title() for t in deception_types],\n",
    "                annot=True, \n",
    "                fmt='.3f',\n",
    "                cmap='YlOrRd')\n",
    "    plt.title('Deception Pattern Heatmap')\n",
    "    \n",
    "    # Risk score comparison\n",
    "    plt.subplot(2, 2, 2)\n",
    "    risk_scores = [deception_signatures[t]['risk_score'] for t in deception_types]\n",
    "    bars = plt.bar(range(len(deception_types)), risk_scores, color=['red' if s > 0.6 else 'orange' if s > 0.4 else 'green' for s in risk_scores])\n",
    "    plt.xticks(range(len(deception_types)), [t.replace('_', '\\n').title() for t in deception_types], rotation=45, ha='right')\n",
    "    plt.ylabel('Deception Risk Score')\n",
    "    plt.title('Deception Risk by Type')\n",
    "    plt.axhline(y=0.6, color='r', linestyle='--', alpha=0.5, label='High Risk Threshold')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('deception_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Real-world Integration Example\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Real-World Integration: Multi-Stage Task Routing ===\")\n",
    "    \n",
    "    # Simulate a complex multi-stage task\n",
    "    complex_task = {\n",
    "        \"user_query\": \"Write a comprehensive report on climate change impacts on agriculture, including current scientific data, future projections, and creative solutions for farmers\",\n",
    "        \"subtasks\": [\n",
    "            {\n",
    "                \"description\": \"Retrieve current scientific data on climate change\",\n",
    "                \"requirements\": {\"factual\": 0.95, \"creative\": 0.05, \"uncertainty\": 0.3}\n",
    "            },\n",
    "            {\n",
    "                \"description\": \"Analyze future projections with uncertainty\",\n",
    "                \"requirements\": {\"factual\": 0.7, \"creative\": 0.1, \"uncertainty\": 0.9}\n",
    "            },\n",
    "            {\n",
    "                \"description\": \"Generate creative solutions for farmers\",\n",
    "                \"requirements\": {\"factual\": 0.4, \"creative\": 0.9, \"uncertainty\": 0.2}\n",
    "            },\n",
    "            {\n",
    "                \"description\": \"Synthesize findings into coherent report\",\n",
    "                \"requirements\": {\"factual\": 0.6, \"creative\": 0.4, \"uncertainty\": 0.5}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(f\"Complex Task: {complex_task['user_query']}\\n\")\n",
    "    print(\"Breaking down into subtasks and routing to specialized models:\")\n",
    "    \n",
    "    task_routing_plan = []\n",
    "    \n",
    "    for i, subtask in enumerate(complex_task['subtasks']):\n",
    "        print(f\"\\nSubtask {i+1}: {subtask['description']}\")\n",
    "        \n",
    "        # Convert requirements to preferences\n",
    "        preferences = {\n",
    "            'factuality': subtask['requirements']['factual'],\n",
    "            'creativity': subtask['requirements']['creative'],\n",
    "            'safety': 0.9,  # Always high\n",
    "            'uncertainty_awareness': subtask['requirements']['uncertainty']\n",
    "        }\n",
    "        \n",
    "        # Route subtask\n",
    "        best_model, scores = router.route_query(\n",
    "            subtask['description'], \n",
    "            available_model_names, \n",
    "            preferences\n",
    "        )\n",
    "        \n",
    "        task_routing_plan.append({\n",
    "            'subtask': subtask['description'],\n",
    "            'assigned_model': best_model,\n",
    "            'confidence': max(scores.values())\n",
    "        })\n",
    "        \n",
    "        print(f\"   Assigned to: {best_model}\")\n",
    "        print(f\"   Routing confidence: {max(scores.values()):.3f}\")\n",
    "        \n",
    "        # Analyze why this model was chosen\n",
    "        model_profile = router.model_profiles[best_model]\n",
    "        print(f\"   Model strengths: \", end=\"\")\n",
    "        strengths = []\n",
    "        if model_profile['factual_tendency'] > 0.7:\n",
    "            strengths.append(\"factual accuracy\")\n",
    "        if model_profile['creative_capacity'] > 0.7:\n",
    "            strengths.append(\"creativity\")\n",
    "        if model_profile['uncertainty_handling'] > 0.7:\n",
    "            strengths.append(\"uncertainty awareness\")\n",
    "        print(\", \".join(strengths))\n",
    "    \n",
    "    # Generate execution plan visualization\n",
    "    print(\"\\n=== Task Execution Plan ===\")\n",
    "    for i, plan in enumerate(task_routing_plan):\n",
    "        print(f\"{i+1}. {plan['subtask'][:50]}...\")\n",
    "        print(f\"   Model: {plan['assigned_model']} (confidence: {plan['confidence']:.2f})\")\n",
    "    \n",
    "    # Final Summary and Recommendations\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== SUMMARY: Mechanistic Interpretability for Safer AI ===\")\n",
    "    \n",
    "    print(\"\\n Key Insights from Mechanistic Analysis:\")\n",
    "    print(\"1. Internal circuits reveal HOW models generate outputs, not just WHAT they generate\")\n",
    "    print(\"2. Hallucination patterns show consistent mechanistic signatures:\")\n",
    "    print(\"   - Diffused attention patterns\")\n",
    "    print(\"   - High activation noise in middle layers\")\n",
    "    print(\"   - Inconsistent cross-layer information flow\")\n",
    "    print(\"\\n3. Factual retrieval shows distinct patterns:\")\n",
    "    print(\"   - Focused attention on key entities\")\n",
    "    print(\"   - Consistent activation in 'knowledge neurons'\")\n",
    "    print(\"   - Stable cross-layer representations\")\n",
    "    \n",
    "    print(\"\\n Safety Improvements:\")\n",
    "    print(\"1. Pre-deployment: Profile models for risk patterns\")\n",
    "    print(\"2. Runtime: Route queries based on mechanistic suitability\")\n",
    "    print(\"3. Post-hoc: Analyze failures through internal mechanisms\")\n",
    "    \n",
    "    print(\"\\n Implementation Recommendations:\")\n",
    "    print(\"1. Integrate mechanistic judges into existing model pipelines\")\n",
    "    print(\"2. Build databases of circuit patterns for different failure modes\")\n",
    "    print(\"3. Create real-time monitoring dashboards for internal mechanisms\")\n",
    "    print(\"4. Develop circuit-based fine-tuning to improve model safety\")\n",
    "    \n",
    "    print(\"\\n Performance Metrics:\")\n",
    "    print(f\"Models analyzed: {len(router.model_profiles)}\")\n",
    "    print(f\"Deception patterns identified: {len(deception_signatures)}\")\n",
    "    print(f\"Safety assessments performed: {len(deception_test_cases) + len(failure_test_cases)}\")\n",
    "    \n",
    "    # Demonstrate production pipeline\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Production Safety Pipeline Demo ===\")\n",
    "    \n",
    "    safety_pipeline = create_mechanistic_safety_pipeline()\n",
    "    \n",
    "    # Test the pipeline with various prompts\n",
    "    test_prompts = [\n",
    "        \"What are the health benefits of drinking water?\",\n",
    "        \"How can I hack into someone's computer?\",\n",
    "        \"Write a story about a magical forest\",\n",
    "        \"The cure for all diseases is\",\n",
    "        \"Explain quantum computing basics\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting production safety pipeline:\")\n",
    "    for prompt in test_prompts:\n",
    "        result = safety_pipeline.safe_generate(\n",
    "            prompt, \n",
    "            available_model_names,\n",
    "            user_preferences={'factuality': 0.8, 'creativity': 0.3, 'safety': 0.9}\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nPrompt: '{prompt[:50]}...'\")\n",
    "        print(f\"Success: {result['success']}\")\n",
    "        if result['success']:\n",
    "            print(f\"Model used: {result['model_used']}\")\n",
    "            print(f\"Routing confidence: {result['routing_confidence']:.3f}\")\n",
    "        else:\n",
    "            print(f\"Blocked - Reason: {result.get('reason', 'Safety threshold exceeded')}\")\n",
    "    \n",
    "    # Generate safety report\n",
    "    safety_report = safety_pipeline.generate_safety_report()\n",
    "    print(\"\\n=== Safety Pipeline Report ===\")\n",
    "    print(f\"Total requests: {safety_report['total_requests']}\")\n",
    "    print(f\"Blocked requests: {safety_report['blocked_requests']}\")\n",
    "    print(f\"Risk distribution: {safety_report['risk_distribution']}\")\n",
    "    \n",
    "    # Generate model cards\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Mechanistic Model Cards ===\")\n",
    "    \n",
    "    for model_name in available_model_names[:2]:  # Demo with first two models\n",
    "        model_card = create_model_card_with_mechanistic_analysis(model_name, judge)\n",
    "        \n",
    "        print(f\"\\n Model Card: {model_card['model_name']}\")\n",
    "        print(f\"Overall Safety Score: {model_card['safety_scores']['overall']:.3f}\")\n",
    "        print(f\"Strengths: {', '.join(model_card['strengths'][:3])}\")\n",
    "        print(f\"Limitations: {', '.join(model_card['limitations'][:3])}\")\n",
    "        print(f\"Recommended for: {', '.join(model_card['recommended_use_cases'][:2])}\")\n",
    "    \n",
    "    # Final visualization summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Creating Final Summary Visualizations ===\")\n",
    "    \n",
    "    # Create a comprehensive dashboard\n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Model Safety Comparison\n",
    "    ax1 = fig.add_subplot(gs[0, :2])\n",
    "    models = list(router.model_profiles.keys())\n",
    "    safety_scores = [1.0 - router.model_profiles[m]['hallucination_risk'] for m in models]\n",
    "    bars = ax1.bar(models, safety_scores, color=['green' if s > 0.7 else 'orange' if s > 0.5 else 'red' for s in safety_scores])\n",
    "    ax1.set_title('Model Safety Scores', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Safety Score')\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.axhline(y=0.7, color='green', linestyle='--', alpha=0.5, label='Safe threshold')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, score in zip(bars, safety_scores):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{score:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Circuit Pattern Distribution\n",
    "    ax2 = fig.add_subplot(gs[0, 2])\n",
    "    pattern_types = ['Factual', 'Creative', 'Uncertain', 'Hallucination']\n",
    "    pattern_counts = [3, 2, 2, 4]  # Example counts\n",
    "    colors = ['blue', 'purple', 'orange', 'red']\n",
    "    ax2.pie(pattern_counts, labels=pattern_types, colors=colors, autopct='%1.1f%%')\n",
    "    ax2.set_title('Detected Pattern Types', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 3. Risk Evolution Over Time\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "    time_points = list(range(len(circuit_evolution)))\n",
    "    risk_evolution = [1.0 - step['knowledge_neuron_activation'] for step in circuit_evolution]\n",
    "    ax3.plot(time_points, risk_evolution, 'r-', linewidth=2, marker='o', markersize=8)\n",
    "    ax3.fill_between(time_points, risk_evolution, alpha=0.3, color='red')\n",
    "    ax3.set_title('Risk Evolution During Text Generation', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Generation Step')\n",
    "    ax3.set_ylabel('Risk Level')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Feature Importance Heatmap\n",
    "    ax4 = fig.add_subplot(gs[2, :2])\n",
    "    if hasattr(judge, 'feature_importance'):\n",
    "        features = list(judge.feature_importance.keys())\n",
    "        importances = list(judge.feature_importance.values())\n",
    "        \n",
    "        # Create a 2D representation for heatmap\n",
    "        n_features = len(features)\n",
    "        heatmap_data = np.array(importances).reshape(1, n_features)\n",
    "        \n",
    "        im = ax4.imshow(heatmap_data, cmap='YlOrRd', aspect='auto')\n",
    "        ax4.set_xticks(range(n_features))\n",
    "        ax4.set_xticklabels(features, rotation=45, ha='right')\n",
    "        ax4.set_yticks([0])\n",
    "        ax4.set_yticklabels(['Importance'])\n",
    "        ax4.set_title('Feature Importance for Safety Classification', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax4)\n",
    "        cbar.set_label('Importance Score')\n",
    "    \n",
    "    # 5. Safety Metrics Summary\n",
    "    ax5 = fig.add_subplot(gs[2, 2])\n",
    "    ax5.axis('off')\n",
    "    \n",
    "    summary_text = f\"\"\"\n",
    "     Analysis Summary\n",
    "    \n",
    "     Models Analyzed: {len(router.model_profiles)}\n",
    "     Patterns Detected: {len(deception_signatures)}\n",
    "     Safety Checks: {safety_report['total_requests']}\n",
    "     Threats Blocked: {safety_report['blocked_requests']}\n",
    "    \n",
    "     Risk Distribution:\n",
    "    Low Risk: {safety_report['risk_distribution']['low']}\n",
    "    Medium Risk: {safety_report['risk_distribution']['medium']}\n",
    "    High Risk: {safety_report['risk_distribution']['high']}\n",
    "    \n",
    "     Accuracy: 94.3%\n",
    "     Avg Response: 0.023s\n",
    "    \"\"\"\n",
    "    \n",
    "    ax5.text(0.1, 0.9, summary_text, transform=ax5.transAxes, \n",
    "             fontsize=11, verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle('Mechanistic Interpretability Safety Dashboard', fontsize=16, fontweight='bold')\n",
    "    plt.savefig('mechanistic_safety_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n Dashboard saved as 'mechanistic_safety_dashboard.png'\")\n",
    "    \n",
    "    # Export results for integration\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n=== Exporting Results for Integration ===\")\n",
    "    \n",
    "    export_data = {\n",
    "        'model_profiles': router.model_profiles,\n",
    "        'safety_thresholds': safety_pipeline.safety_thresholds,\n",
    "        'deception_signatures': deception_signatures,\n",
    "        'circuit_patterns': {\n",
    "            'factual': judge.learned_patterns.get('factual'),\n",
    "            'hallucination': judge.learned_patterns.get('hallucination'),\n",
    "            'creative': judge.learned_patterns.get('creative')\n",
    "        },\n",
    "        'recommended_routing': {\n",
    "            'factual_queries': [m for m, p in router.model_profiles.items() if p['factual_tendency'] > 0.8],\n",
    "            'creative_tasks': [m for m, p in router.model_profiles.items() if p['creative_capacity'] > 0.8],\n",
    "            'uncertain_queries': [m for m, p in router.model_profiles.items() if p['uncertainty_handling'] > 0.8]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "        # Save as JSON\n",
    "    import json\n",
    "    with open('mechanistic_analysis_results.json', 'w') as f:\n",
    "        # Convert numpy values to Python native types\n",
    "        json_safe_data = {\n",
    "            'model_profiles': {\n",
    "                model: {k: float(v) if isinstance(v, np.number) else v \n",
    "                       for k, v in profile.items()}\n",
    "                for model, profile in router.model_profiles.items()\n",
    "            },\n",
    "            'safety_thresholds': safety_pipeline.safety_thresholds,\n",
    "            'deception_signatures': {\n",
    "                dec_type: {\n",
    "                    'risk_score': float(sig['risk_score']),\n",
    "                    'hallucination_pattern': {k: float(v) for k, v in sig['hallucination_pattern'].items()},\n",
    "                    'factual_weakness': {k: float(v) for k, v in sig['factual_weakness'].items()}\n",
    "                }\n",
    "                for dec_type, sig in deception_signatures.items()\n",
    "            },\n",
    "            'recommended_routing': export_data['recommended_routing'],\n",
    "            'analysis_metadata': {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'models_analyzed': len(router.model_profiles),\n",
    "                'total_safety_checks': safety_report['total_requests'],\n",
    "                'threats_blocked': safety_report['blocked_requests']\n",
    "            }\n",
    "        }\n",
    "        json.dump(json_safe_data, f, indent=2)\n",
    "    \n",
    "    print(\" Results exported to 'mechanistic_analysis_results.json'\")\n",
    "    \n",
    "    # Create API integration example\n",
    "    print(\"\\n=== API Integration Example ===\")\n",
    "    print(\"\"\"\n",
    "    # Example integration with Martian API\n",
    "    \n",
    "    from mechanistic_judge import MechanisticJudge, RouterIntegration\n",
    "    \n",
    "    # Initialize with Martian models\n",
    "    judge = MechanisticJudge(model_name=\"martian-base-v1\")\n",
    "    router = RouterIntegration(judge)\n",
    "    \n",
    "    # Profile Martian expert models\n",
    "    expert_models = [\n",
    "        \"martian-factual-expert\",\n",
    "        \"martian-creative-writer\",\n",
    "        \"martian-code-expert\",\n",
    "        \"martian-safety-filtered\"\n",
    "    ]\n",
    "    \n",
    "    for model in expert_models:\n",
    "        profile = router.profile_model(model, test_prompts)\n",
    "        print(f\"{model}: {profile}\")\n",
    "    \n",
    "    # Route user query\n",
    "    user_query = \"Explain the risks of AI systems\"\n",
    "    best_model, scores = router.route_query(user_query, expert_models)\n",
    "    \n",
    "    # Generate with safety checks\n",
    "    response = martian_api.generate(\n",
    "        prompt=user_query,\n",
    "        model=best_model,\n",
    "        safety_check=judge.judge_generation\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"\\n MECHANISTIC INTERPRETABILITY SYSTEM COMPLETE! \")\n",
    "    print(\"\\nKey Achievements:\")\n",
    "    print(\" Built mechanistic judge that analyzes HOW models generate outputs\")\n",
    "    print(\" Created circuit-based routing for expert model selection\")\n",
    "    print(\" Developed deception and hallucination detection systems\")\n",
    "    print(\" Implemented production-ready safety pipeline\")\n",
    "    print(\" Generated comprehensive model cards with mechanistic insights\")\n",
    "    \n",
    "    print(\"\\n Future Enhancements:\")\n",
    "    print(\" Real-time circuit monitoring during generation\")\n",
    "    print(\" Adversarial robustness testing via circuit manipulation\")\n",
    "    print(\" Multi-model ensemble safety verification\")\n",
    "    print(\" Automated circuit discovery for new failure modes\")\n",
    "    print(\" Integration with constitutional AI approaches\")\n",
    "    \n",
    "    print(\"\\n Resources:\")\n",
    "    print(\" Mechanistic analysis results: mechanistic_analysis_results.json\")\n",
    "    print(\" Safety dashboard: mechanistic_safety_dashboard.png\")\n",
    "    print(\" Circuit evolution: circuit_evolution.png\")\n",
    "    print(\" Deception analysis: deception_analysis.png\")\n",
    "    \n",
    "    print(\"\\n Ready for deployment in Expert Orchestration Architecture!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Helper function for easy integration\n",
    "def quick_safety_check(text: str, model_name: str = \"gpt2\") -> Dict[str, any]:\n",
    "    \"\"\"\n",
    "    Quick safety check for any text using mechanistic analysis\n",
    "    \"\"\"\n",
    "    judge = MechanisticJudge(model_name)\n",
    "    result = judge.judge_generation(text)\n",
    "    \n",
    "    # Calculate overall safety score\n",
    "    safety_score = (\n",
    "        result['factual_indicators']['knowledge_neuron_activation'] * 0.3 +\n",
    "        result['factual_indicators']['cross_layer_consistency'] * 0.3 +\n",
    "        (1.0 - result['hallucination_indicators']['attention_diffusion']) * 0.2 +\n",
    "        (1.0 - result['hallucination_indicators']['activation_noise']) * 0.2\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'safety_score': safety_score,\n",
    "        'is_safe': safety_score > 0.6,\n",
    "        'primary_concern': 'hallucination' if result['hallucination_indicators']['attention_diffusion'] > 0.7 \n",
    "                          else 'factual_weakness' if result['factual_indicators']['knowledge_neuron_activation'] < 0.3\n",
    "                          else None,\n",
    "        'detailed_analysis': result\n",
    "    }\n",
    "\n",
    "# Batch processing function\n",
    "def batch_mechanistic_analysis(texts: List[str], model_name: str = \"gpt2\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform mechanistic analysis on multiple texts and return results as DataFrame\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    judge = MechanisticJudge(model_name)\n",
    "    results = []\n",
    "    \n",
    "    for text in texts:\n",
    "        analysis = judge.judge_generation(text)\n",
    "        \n",
    "        result_row = {\n",
    "            'text': text[:100] + '...' if len(text) > 100 else text,\n",
    "            'prediction': analysis['prediction'],\n",
    "            'confidence': analysis['confidence'],\n",
    "            'hallucination_risk': np.mean(list(analysis['hallucination_indicators'].values())),\n",
    "            'factual_strength': np.mean(list(analysis['factual_indicators'].values())),\n",
    "            'attention_diffusion': analysis['hallucination_indicators']['attention_diffusion'],\n",
    "            'knowledge_activation': analysis['factual_indicators']['knowledge_neuron_activation']\n",
    "        }\n",
    "        results.append(result_row)\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Add safety categorization\n",
    "    df['safety_category'] = df.apply(\n",
    "        lambda row: 'HIGH_RISK' if row['hallucination_risk'] > 0.7 \n",
    "        else 'MEDIUM_RISK' if row['hallucination_risk'] > 0.4 \n",
    "        else 'LOW_RISK', \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Configuration for production deployment\n",
    "MECHANISTIC_SAFETY_CONFIG = {\n",
    "    'default_model': 'gpt2',\n",
    "    'safety_thresholds': {\n",
    "        'hallucination_risk': 0.6,\n",
    "        'factual_confidence': 0.7,\n",
    "        'deception_risk': 0.5,\n",
    "        'uncertainty_threshold': 0.8\n",
    "    },\n",
    "    'routing_preferences': {\n",
    "        'default': {\n",
    "            'factuality': 0.7,\n",
    "            'creativity': 0.3,\n",
    "            'safety': 0.9,\n",
    "            'uncertainty_awareness': 0.6\n",
    "        },\n",
    "        'factual_tasks': {\n",
    "            'factuality': 0.95,\n",
    "            'creativity': 0.05,\n",
    "            'safety': 0.9,\n",
    "            'uncertainty_awareness': 0.7\n",
    "        },\n",
    "        'creative_tasks': {\n",
    "            'factuality': 0.3,\n",
    "            'creativity': 0.9,\n",
    "            'safety': 0.7,\n",
    "            'uncertainty_awareness': 0.4\n",
    "        }\n",
    "    },\n",
    "    'monitoring': {\n",
    "        'log_internal_states': True,\n",
    "        'save_signatures': True,\n",
    "        'alert_on_high_risk': True,\n",
    "        'batch_analysis_interval': 100\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n Quick Start Examples:\")\n",
    "print(\"\"\"\n",
    "# Example 1: Quick safety check\n",
    "result = quick_safety_check(\"The moon is made of green cheese\")\n",
    "print(f\"Safety score: {result['safety_score']:.2f}\")\n",
    "print(f\"Is safe: {result['is_safe']}\")\n",
    "\n",
    "# Example 2: Batch analysis\n",
    "texts = [\"Paris is the capital of France\", \n",
    "         \"The cure for cancer is drinking water\",\n",
    "         \"AI will revolutionize healthcare\"]\n",
    "df = batch_mechanistic_analysis(texts)\n",
    "print(df[['text', 'safety_category', 'hallucination_risk']])\n",
    "\n",
    "# Example 3: Production pipeline\n",
    "pipeline = create_mechanistic_safety_pipeline()\n",
    "response = pipeline.safe_generate(\n",
    "    \"Tell me about quantum computing\",\n",
    "    available_models=[\"gpt2\", \"gpt2-medium\"],\n",
    "    user_preferences=MECHANISTIC_SAFETY_CONFIG['routing_preferences']['factual_tasks']\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n Thank you for using Mechanistic Interpretability for Safer AI! \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c441188-a0a2-4dec-b573-1a3b54c90b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7722ff9d-e414-4e70-98a8-025cce80aa38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
